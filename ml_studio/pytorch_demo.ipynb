{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Demo: Wine Quality Prediction Model Training\n",
    "\n",
    "This notebook demonstrates how to use PyTorch within Azure Machine Learning Studio notebooks, leveraging their built-in PyTorch environments.\n",
    "\n",
    "In this example, we use the wine quality dataset to show how you can use Azure Machine Learning for a regression problem with PyTorch neural networks. The goal is to predict wine quality (score 0-10) based on physicochemical properties like acidity, sugar content, alcohol level, etc.\n",
    "\n",
    "## Learning Objectives:\n",
    "- Set up and verify PyTorch environment in Azure ML\n",
    "- Load and preprocess data for deep learning\n",
    "- Build a simple neural network for regression\n",
    "- Train and evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "You need a compute instance to run the code as it relies upon a custom environment that is not available with \"Serverless Spark Compute\". If you don't have a compute instance, select **Create compute** on the toolbar to first create one.  You can use all the default settings. \n",
    "\n",
    "## Set your kernel\n",
    "\n",
    "* If your compute instance is stopped, start it now.  \n",
    "        \n",
    "* Once your compute instance is running, make sure the that the kernel, found on the top right, is `Python 3.10 - AzureML`.  If not, use the dropdown to select this kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Imports\n",
    "\n",
    "First, let's verify our PyTorch installation and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Sklearn for preprocessing and metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Check PyTorch version and CUDA availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we're using the free subscription compute we won't be able to use CUDA as we lack GPU's. If you wish to use GPU's speak to your IT department for access under your university/institute's Azure tenant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Wine Quality Dataset\n",
    "\n",
    "For this demo, we'll use the UCI Wine Quality dataset. You can access this dataset using a web URL, however in a typical Azure ML scenario you would load this from your Azure storage. Here we'll show both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading from your Azure storage\n",
    "# 1. In the upper right Azure Machine Learning studio toolbar, select your workspace name.\n",
    "# 2. Copy the value for workspace, resource group and subscription ID into the code.\n",
    "# This will only work if you have a dataset called 'wine_quality_kaggle' in your workspace storage\n",
    "\n",
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "subscription_id = \"SUBSCRIPTION ID HERE\"\n",
    "resource_group = \"RESOURCE NAME HERE\"\n",
    "workspace_name = \"WORKSPACE NAME HERE\"\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name='wine_quality_kaggle')\n",
    "wine_data = dataset.to_pandas_dataframe()\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {wine_data.shape}\")\n",
    "print(f\"\\nColumn names: {wine_data.columns.tolist()}\")\n",
    "print(f\"\\nQuality distribution:\")\n",
    "print(wine_data['quality'].value_counts().sort_index())\n",
    "\n",
    "# Show first few rows\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a quick and easy application of this code head to the data section in ML studio, find your dataset and click on the \"consume\" tab. Here, under the 'Interactive Development\" drop-down you'll find the code needed to access your data. \n",
    "\n",
    "For more information on importing data in Azure, head to the explore-data.ipynb notebook from the getting-started section in Azure ML Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> We can also load our data via a URL if that is an option to you</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wine quality dataset for URL\n",
    "# For this demo, choose this option\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "wine_data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {wine_data.shape}\")\n",
    "print(f\"\\nColumn names: {wine_data.columns.tolist()}\")\n",
    "print(f\"\\nQuality distribution:\")\n",
    "print(wine_data['quality'].value_counts().sort_index())\n",
    "\n",
    "# Show first few rows\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Preprocessing step is crucial for neural network training. We separate our features (wine properties) from our target variable (quality score), split the data into training and testing sets to evaluate model performance, and apply standardisation to normalise all features to have zero mean and unit variance. This standardisation ensures that no single feature dominates the learning process due to its scale. Finally, we convert our data to PyTorch tensors and create DataLoaders that will efficiently batch and shuffle our data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = wine_data.drop('quality', axis=1).values\n",
    "y = wine_data['quality'].values\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardise features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "# Create PyTorch datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>What is a tensor?</strong>\n",
    "\n",
    "A tensor is a mathematical object that generalises familiar concepts like numbers, vectors, and matrices. Think of it as a container for data that can have different dimensions - a single number (0D), a list of numbers (1D), a table of numbers (2D), or even higher-dimensional arrangements. In machine learning, tensors are fundamental because they provide a unified way to represent and manipulate the complex, multi-dimensional data that neural networks process, from simple input features to the intricate weight matrices that define how networks learn and make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the Neural Network Model\n",
    "\n",
    "Create a simple feedforward neural network for wine quality prediction.\n",
    "\n",
    "**Neural Network Architecture Explanation:**\n",
    "\n",
    "Our `WineQualityNet` is a feedforward neural network with four fully connected (linear) layers that progressively reduce the dimensionality: input → 64 → 32 → 16 → 1 neuron. This architecture creates a funnel-like structure that learns to extract increasingly abstract features from the wine properties to predict quality. We use ReLU (Rectified Linear Unit) activation functions between layers to introduce non-linearity, allowing the network to learn complex patterns. Dropout layers (20% probability) are included to prevent overfitting by randomly setting some neurons to zero during training, forcing the network to be more robust and generalisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineQualityNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(WineQualityNet, self).__init__()\n",
    "        \n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "        \n",
    "        # Activation and dropout\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = WineQualityNet(input_dim=X_train.shape[1]).to(device)\n",
    "\n",
    "# Display model architecture\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Setup\n",
    "\n",
    "Configure loss function, optimiser, and training parameters.\n",
    "\n",
    "**Key Components Explained:**\n",
    "\n",
    "**MSE (Mean Squared Error):** Our loss function that measures the average squared difference between predicted and actual wine quality scores. MSE is ideal for regression problems as it penalises larger errors more heavily and provides smooth gradients for optimisation.\n",
    "\n",
    "**Adam Optimiser:** An adaptive learning rate optimiser that combines the benefits of momentum and RMSprop. Adam automatically adjusts the learning rate for each parameter individually, making it very effective for training neural networks with minimal hyperparameter tuning.\n",
    "\n",
    "**Training Functions:** The `train_epoch` function performs forward propagation (calculating predictions), computes the loss, and uses backpropagation to update model weights. The `validate` function evaluates model performance on unseen data without updating weights, helping us monitor for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_X, batch_y in dataloader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X).squeeze()\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Validation function\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X).squeeze()\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the Model\n",
    "\n",
    "Train the neural network and monitor performance by calling the previous functions per training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss = validate(model, test_loader, criterion, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualise Training Progress\n",
    "\n",
    "**What we expect to see:** \n",
    "Both training and validation loss should decrease over time, indicating the model is learning. Ideally, both curves should converge to a similar low value. If the training loss continues decreasing while validation loss increases, this indicates overfitting. If both curves plateau at a high value, the model may be underfitting and need more complexity or different hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation\n",
    "\n",
    "Evaluate the model's performance on the test set.\n",
    "\n",
    "**Metrics Explained:**\n",
    "\n",
    "**MSE (Mean Squared Error):** The average of squared differences between predicted and actual values. Lower values indicate better performance.\n",
    "\n",
    "**RMSE (Root Mean Squared Error):** The square root of MSE, expressed in the same units as our target variable (wine quality scores). For wine quality (scale 0-10), an RMSE of 0.5-0.7 would be considered good.\n",
    "\n",
    "**R² Score:** Coefficient of determination indicating how much variance in the target variable is explained by the model. Values closer to 1.0 indicate better performance.\n",
    "\n",
    "**What we expect to see:** A scatter plot where points cluster around the diagonal line (perfect predictions), with minimal spread. The error distribution should be roughly normal and centered around zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_device = X_test_tensor.to(device)\n",
    "    predictions = model(X_test_device).squeeze().cpu().numpy()\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f\"Test Set Performance:\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Visualization of predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, predictions, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Quality')\n",
    "plt.ylabel('Predicted Quality')\n",
    "plt.title('Actual vs Predicted Wine Quality')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Distribution of prediction errors\n",
    "errors = predictions - y_test\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(errors, bins=30, edgecolor='black')\n",
    "plt.xlabel('Prediction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Prediction Errors')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save the Model to the local folder\n",
    "\n",
    "You would typically save the model to a local file for recall at another time for further trainging or predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model as a .pth file in the current directory\n",
    "model_path = 'wine_quality_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scaler': scaler,\n",
    "    'input_dim': X_train.shape[1],\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses\n",
    "}, model_path)\n",
    "\n",
    "\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the model as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the models paramters \n",
    "checkpoint = torch.load('./wine_quality_model.pth')\n",
    "\n",
    "# Grab the input dimensions and intialise the model\n",
    "input_dim = checkpoint['input_dim']\n",
    "model = WineQualityNet(input_dim=input_dim)\n",
    "\n",
    "# Load the model state dictionary\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Move to appropriate device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Load the models parameters\n",
    "model.load_state_dict(torch.load('path/to/your/model.pth'))\n",
    "\n",
    "# Set to evaluation mode for predictions (it switches off the drop-out layers so all neurons are active)\n",
    "# If you are training further, forgo this step\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "### What we've accomplished:\n",
    "- ✅ Set up PyTorch in Azure ML environment\n",
    "- ✅ Loaded and preprocessed wine quality data\n",
    "- ✅ Built a simple neural network for regression\n",
    "- ✅ Trained and evaluated the model\n",
    "- ✅ Visualised results and saved the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (PyTorch)",
   "language": "python",
   "name": "python3-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
